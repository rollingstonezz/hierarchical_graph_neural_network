{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b18e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.5.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv, GINConv, GraphConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from itertools import combinations\n",
    "import time\n",
    "from torch.nn import Embedding, Sequential, Linear, ModuleList, ReLU\n",
    "import argparse\n",
    "import os, sys\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from torch.autograd import Variable\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from networkx.algorithms.components import strongly_connected_components\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from sklearn.metrics import f1_score\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.loader import ClusterData, ClusterLoader, DataLoader\n",
    "from torch_geometric.nn import BatchNorm, SAGEConv\n",
    "import os.path as osp\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import TUDataset, MoleculeNet, GEDDataset\n",
    "from utils.GNNBenchmarkDataset import GNNBenchmarkDataset\n",
    "from utils.UPFD import UPFD\n",
    "from torch_geometric.loader import ClusterData, ClusterLoader, DataLoader, ShaDowKHopSampler\n",
    "from torch_geometric.nn import BatchNorm, SAGEConv\n",
    "from torch_geometric.utils import contains_isolated_nodes\n",
    "from torch_sparse import SparseTensor, cat\n",
    "from torch_scatter import scatter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from models.model import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8e7697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_dir = '../../data'\n",
    "        self.save_dir = '../../data/processed'\n",
    "        self.write_dir = '.results/processed'\n",
    "        self.dataset = 'MUTAG'\n",
    "        self.idx = 1\n",
    "        self.gpu = 0\n",
    "        self.num_clusters = 5\n",
    "        self.hidden_dim = 64\n",
    "        self.number_layers = 2\n",
    "        self.lr = 5e-4\n",
    "        \n",
    "args = Args()\n",
    "\n",
    "dataset_name = args.dataset\n",
    "DATA_PATH = args.data_dir\n",
    "idx = args.idx\n",
    "\n",
    "if dataset_name in ['DD', 'MUTAG', 'PROTEINS', 'IMDB-BINARY', 'IMDB-MULTI', 'REDDIT-BINARY', 'COLLAB']:\n",
    "    path = osp.join(DATA_PATH, 'TUDataset')\n",
    "    dataset = TUDataset(path, name=dataset_name)\n",
    "    num_splits = 10\n",
    "elif dataset_name in ['brain']:\n",
    "    path = osp.join(DATA_PATH, 'brain')\n",
    "    with open(os.path.join(path, 'sc.pkl'), 'rb') as f:\n",
    "        dataset = pkl.load(f)\n",
    "    num_splits = 10\n",
    "elif dataset_name in ['UPFD']:\n",
    "    path = osp.join(DATA_PATH, 'UPFD')\n",
    "    dataset_train = UPFD(path, feature='content', name='politifact', split='train')\n",
    "    dataset_val = UPFD(path, feature='content', name='politifact', split='val')\n",
    "    dataset_test = UPFD(path, feature='content', name='politifact', split='test')\n",
    "elif dataset_name in ['MNIST', 'CIFAR10']:\n",
    "    path = osp.join(DATA_PATH, 'GNNBenchmarkDataset')\n",
    "    dataset_train = GNNBenchmarkDataset(path, name=dataset_name, split='train')\n",
    "    dataset_val = GNNBenchmarkDataset(path, name=dataset_name, split='val')\n",
    "    dataset_test = GNNBenchmarkDataset(path, name=dataset_name, split='test')\n",
    "elif dataset_name in ['hiv', 'bace', 'bbbp']:\n",
    "    path = osp.join(DATA_PATH, 'PygGraphPropPredDataset')\n",
    "    dataset = PygGraphPropPredDataset(name = 'ogbg-mol'+dataset_name, root = path)   \n",
    "    split_indices = dataset.get_idx_split() \n",
    "    train_indices = split_indices[\"train\"]\n",
    "    val_indices = split_indices[\"valid\"]\n",
    "    test_indices = split_indices[\"test\"]\n",
    "    dataset_train = dataset[train_indices]\n",
    "    dataset_val = dataset[val_indices]\n",
    "    dataset_test = dataset[test_indices]\n",
    "if idx>1 and not dataset_name in ['DD', 'MUTAG', 'PROTEINS', 'IMDB-BINARY', 'IMDB-MULTI','COLLAB', 'brain', 'REDDIT-BINARY']:\n",
    "    raise ValueError(dataset_name + 'does not have 10-fold validation.')\n",
    "    exit()\n",
    "\n",
    "if dataset_name in ['MNIST', 'CIFAR10', 'hiv', 'bace', 'bbbp', 'UPFD']:\n",
    "\n",
    "    path = osp.join(args.save_dir, dataset_name)\n",
    "\n",
    "    assert os.path.exists(path)\n",
    "\n",
    "    with open(osp.join(path, 'batched_data_cluster'+str(args.num_clusters)+'.pkl'), 'rb') as f:\n",
    "        store_dataset = pkl.load(f)\n",
    "\n",
    "    batched_dataset_train_node = store_dataset['batched_dataset_train_node']\n",
    "    batched_dataset_train_edge = store_dataset['batched_dataset_train_edge']\n",
    "    clustered_edge_index_train = store_dataset['clustered_edge_index_train']\n",
    "    clustered_batch_train = store_dataset['clustered_batch_train']\n",
    "    y_true_train = store_dataset['y_true_train']\n",
    "    batched_dataset_val_node = store_dataset['batched_dataset_val_node']\n",
    "    batched_dataset_val_edge = store_dataset['batched_dataset_val_edge']\n",
    "    clustered_edge_index_val = store_dataset['clustered_edge_index_val']\n",
    "    clustered_batch_val = store_dataset['clustered_batch_val']\n",
    "    y_true_val = store_dataset['y_true_val']\n",
    "    batched_dataset_test_node = store_dataset['batched_dataset_test_node']\n",
    "    batched_dataset_test_edge = store_dataset['batched_dataset_test_edge']\n",
    "    clustered_edge_index_test = store_dataset['clustered_edge_index_test']\n",
    "    clustered_batch_test = store_dataset['clustered_batch_test']\n",
    "    y_true_test = store_dataset['y_true_test']\n",
    "elif dataset_name in ['DD', 'MUTAG', 'PROTEINS', 'IMDB-BINARY', 'IMDB-MULTI','COLLAB', 'brain', 'REDDIT-BINARY']:\n",
    "    i = idx\n",
    "    path = osp.join(args.save_dir, dataset_name)\n",
    "    with open(osp.join(path, 'batched_data_'+str(i)+'_cluster'+str(args.num_clusters)+'.pkl'), 'rb') as f:\n",
    "        store_dataset = pkl.load(f)\n",
    "\n",
    "    batched_dataset_train_node = store_dataset['batched_dataset_train_node']\n",
    "    batched_dataset_train_edge = store_dataset['batched_dataset_train_edge']\n",
    "    clustered_edge_index_train = store_dataset['clustered_edge_index_train']\n",
    "    clustered_batch_train = store_dataset['clustered_batch_train']\n",
    "    y_true_train = store_dataset['y_true_train']\n",
    "    batched_dataset_test_node = store_dataset['batched_dataset_test_node']\n",
    "    batched_dataset_test_edge = store_dataset['batched_dataset_test_edge']\n",
    "    clustered_edge_index_test = store_dataset['clustered_edge_index_test']\n",
    "    clustered_batch_test = store_dataset['clustered_batch_test']\n",
    "    y_true_test = store_dataset['y_true_test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54173c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MUTAG(188)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55272e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dataset = DataLoader(dataset, batch_size=len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d914066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in batched_dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f268b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import WLConv\n",
    "wlconv = WLConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ace6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_x_first = wlconv(\n",
    "    torch.ones((data.num_nodes), dtype=torch.long), \n",
    "    data.edge_index\n",
    ")\n",
    "hashed_x_second = wlconv(\n",
    "    hashed_x_first, \n",
    "    data.edge_index\n",
    ")\n",
    "hist = wlconv.histogram(hashed_x_second, data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e25de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_num_nodes = int(torch.max(clustered_edge_index_train[0])+1)\n",
    "coarse_hashed_x_first = wlconv(\n",
    "    torch.ones((coarse_num_nodes), dtype=torch.long), \n",
    "    clustered_edge_index_train[0]\n",
    ")\n",
    "coarse_hashed_x_second = wlconv(\n",
    "    coarse_hashed_x_first, \n",
    "    clustered_edge_index_train[0]\n",
    ")\n",
    "coarse_hist = wlconv.histogram(coarse_hashed_x_second, clustered_batch_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7aa4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_hist_normalized = hist.sum(axis=0)\n",
    "coarse_hist_normalized = coarse_hist.sum(axis=0)\n",
    "fine_hist_normalized = fine_hist_normalized / fine_hist_normalized.sum()\n",
    "coarse_hist_normalized = coarse_hist_normalized / coarse_hist_normalized.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97fd2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_hist_normalized_np = fine_hist_normalized.numpy()\n",
    "coarse_hist_normalized_np = coarse_hist_normalized.numpy()\n",
    "longlength = max(len(fine_hist_normalized_np), len(coarse_hist_normalized_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a638942",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_hist_normalized_np = np.concatenate([fine_hist_normalized_np, np.zeros(longlength - len(fine_hist_normalized_np))])\n",
    "coarse_hist_normalized_np = np.concatenate([coarse_hist_normalized_np, np.zeros(longlength - len(coarse_hist_normalized_np))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8255d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.66778588],\n",
       "       [0.66778588, 1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(fine_hist_normalized_np, coarse_hist_normalized_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263f9ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAO7klEQVR4nO3df6ieZ33H8fdnp4aNrKKzxx8kcacbYRKkdeUQhYpaWEti/4gb22gRf2HJCg3qH4Jhfzi3MQjDjW1QDZkLKKwrgmYLa7SVseGkdsuJdG1TjTvEbD1LNafW6YpgzfrdH88dfTh7zjn3yfn5XH2/4PA89/XjPtfFRT7nznXu5z6pKiRJ7fqZzR6AJGl9GfSS1DiDXpIaZ9BLUuMMeklq3DWbPYBRrrvuupqamtrsYUjS2Dhz5swzVTU5qm5LBv3U1BQzMzObPQxJGhtJ/mOxOrduJKlxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY3rFfRJ9iU5l2Q2yeER9e9M8lj39XCSG4fqLiR5PMmjSfwUlCRtsGU/GZtkArgXuBWYA04nOVlVTw41+xbw1qr6XpL9wDHgjUP1t1TVM2s47heFqcMPLFl/4cjtGzQSSeOszxX9XmC2qs5X1fPA/cCB4QZV9XBVfa87fATYubbDlCRdrT5BvwN4auh4ritbzPuBLwwdF/BQkjNJDi7WKcnBJDNJZubn53sMS5LUR5+HmmVE2cg/NJvkFgZB/+ah4pur6mKSVwJfSvKNqvry/zth1TEGWz5MT0/7h2wlaY30uaKfA3YNHe8ELi5slOQG4FPAgar67pXyqrrYvV4CTjDYCpIkbZA+QX8a2J3k+iTbgDuAk8MNkrwW+Dzwrqr65lD59iTXXnkP3AY8sVaDlyQtb9mtm6q6nOQQ8CAwARyvqrNJ7u7qjwIfBV4BfCIJwOWqmgZeBZzoyq4B7quqL67LTCRJI/X6wyNVdQo4taDs6ND7u4C7RvQ7D9y4sFyStHH8ZKwkNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcb2CPsm+JOeSzCY5PKL+nUke674eTnJj376SpPW1bNAnmQDuBfYDe4A7k+xZ0OxbwFur6gbgD4FjK+grSVpHfa7o9wKzVXW+qp4H7gcODDeoqoer6nvd4SPAzr59JUnrq0/Q7wCeGjqe68oW837gCyvtm+RgkpkkM/Pz8z2GJUnqo0/QZ0RZjWyY3MIg6D+y0r5VdayqpqtqenJyssewJEl9XNOjzRywa+h4J3BxYaMkNwCfAvZX1XdX0leStH76XNGfBnYnuT7JNuAO4ORwgySvBT4PvKuqvrmSvpKk9bXsFX1VXU5yCHgQmACOV9XZJHd39UeBjwKvAD6RBOBytw0zsu86zUWSNEKfrRuq6hRwakHZ0aH3dwF39e0rSdo4fjJWkhpn0EtS43pt3UirNXX4gSXrLxy5fYNGIr34eEUvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4XkGfZF+Sc0lmkxweUf+6JF9N8qMkH15QdyHJ40keTTKzVgOXJPVzzXINkkwA9wK3AnPA6SQnq+rJoWbPAh8A3rHIaW6pqmdWOVZJ0lXoc0W/F5itqvNV9TxwP3BguEFVXaqq08CP12GMkqRV6BP0O4Cnho7nurK+CngoyZkkBxdrlORgkpkkM/Pz8ys4vSRpKX2CPiPKagXf4+aqugnYD9yT5C2jGlXVsaqarqrpycnJFZxekrSUPkE/B+waOt4JXOz7DarqYvd6CTjBYCtIkrRB+gT9aWB3kuuTbAPuAE72OXmS7UmuvfIeuA144moHK0lauWXvuqmqy0kOAQ8CE8Dxqjqb5O6u/miSVwMzwEuBF5J8CNgDXAecSHLle91XVV9cl5lIkkZaNugBquoUcGpB2dGh999msKWz0A+AG1czQEnS6vjJWElqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUuF6PKdbWNnX4gSXrLxy5fYNGImkr8opekhpn0EtS49y6eRFxi0d6cfKKXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1rlfQJ9mX5FyS2SSHR9S/LslXk/woyYdX0leStL6WDfokE8C9wH5gD3Bnkj0Lmj0LfAD4+FX0lSStoz5X9HuB2ao6X1XPA/cDB4YbVNWlqjoN/HilfSVJ66tP0O8Anho6nuvK+ujdN8nBJDNJZubn53ueXpK0nD5BnxFl1fP8vftW1bGqmq6q6cnJyZ6nlyQtp0/QzwG7ho53Ahd7nn81fSVJa6BP0J8Gdie5Psk24A7gZM/zr6avJGkNXLNcg6q6nOQQ8CAwARyvqrNJ7u7qjyZ5NTADvBR4IcmHgD1V9YNRfddpLpKkEZYNeoCqOgWcWlB2dOj9txlsy/TqK0naOH4yVpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGtfrk7HSYqYOP7Bk/YUjt2/QSCQtxit6SWqcQS9JjXPrRiO5JSO1wyt6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1Dhvr9wE3rooaSN5RS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxvUK+iT7kpxLMpvk8Ij6JPmLrv6xJDcN1V1I8niSR5PMrOXgJUnLW/bplUkmgHuBW4E54HSSk1X15FCz/cDu7uuNwCe71ytuqapn1mzUkqTe+lzR7wVmq+p8VT0P3A8cWNDmAPCZGngEeFmS16zxWCVJV6FP0O8Anho6nuvK+rYp4KEkZ5IcXOybJDmYZCbJzPz8fI9hSZL66BP0GVFWK2hzc1XdxGB7554kbxn1TarqWFVNV9X05ORkj2FJkvroE/RzwK6h453Axb5tqurK6yXgBIOtIEnSBukT9KeB3UmuT7INuAM4uaDNSeDd3d03bwK+X1VPJ9me5FqAJNuB24An1nD8kqRlLHvXTVVdTnIIeBCYAI5X1dkkd3f1R4FTwNuBWeCHwPu67q8CTiS58r3uq6ovrvksJEmL6vXHwavqFIMwHy47OvS+gHtG9DsP3LjKMUqSVqFX0Ldo6vADS9ZfOHL7Bo1EktaXj0CQpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNu2azByANmzr8wJL1F47cvkEjkdrhFb0kNc6gl6TGGfSS1DiDXpIaZ9BLUuO860Zjabm7c8A7dKQrvKKXpMZ5RS91+t7D773+Gje9gj7JPuDPgQngU1V1ZEF9uvq3Az8E3ltVX+vTV2rVWv3gGG4rXY1lt26STAD3AvuBPcCdSfYsaLYf2N19HQQ+uYK+kqR11OeKfi8wW1XnAZLcDxwAnhxqcwD4TFUV8EiSlyV5DTDVo6+0rtxqWZzbVS8OGWTzEg2S3wT2VdVd3fG7gDdW1aGhNn8PHKmqr3TH/wB8hEHQL9l36BwHGfxvAOBXgHOrm9pPXAc8s0bn2mzOZWtyLlvTi20uv1hVk6Mq+lzRZ0TZwp8Oi7Xp03dQWHUMONZjPCuSZKaqptf6vJvBuWxNzmVrci4/1Sfo54BdQ8c7gYs922zr0VeStI763Ed/Gtid5Pok24A7gJML2pwE3p2BNwHfr6qne/aVJK2jZa/oq+pykkPAgwxukTxeVWeT3N3VHwVOMbi1cpbB7ZXvW6rvusxkcWu+HbSJnMvW5Fy2JufSWfaXsZKk8eYjECSpcQa9JDWu2aBPsi/JuSSzSQ5v9nhWK8mFJI8neTTJzGaPZyWSHE9yKckTQ2W/kORLSf69e335Zo6xr0Xm8rEk/9WtzaNJ3r6ZY+wrya4k/5jk60nOJvlgVz52a7PEXMZubZL8bJJ/TfJv3Vx+vyu/6nVpco++e/TCN4FbGdz6eRq4s6rG9hO5SS4A01U1dh8ASfIW4DkGn55+fVf2x8CzVXWk+0H88qr6yGaOs49F5vIx4Lmq+vhmjm2luk+vv6aqvpbkWuAM8A7gvYzZ2iwxl99mzName3bY9qp6LslLgK8AHwR+g6tcl1av6H/y2Iaqeh648ugFbYKq+jLw7ILiA8Cnu/efZvCPcstbZC5jqaqevvLwwar6H+DrwA7GcG2WmMvYqYHnusOXdF/FKtal1aDfATw1dDzHmC76kAIeSnKme1zEuHtV91kLutdXbvJ4VutQkse6rZ0tv9WxUJIp4FeBf2HM12bBXGAM1ybJRJJHgUvAl6pqVevSatD3fvTCGLm5qm5i8CTQe7otBG0NnwR+GXgD8DTwJ5s6mhVK8vPA54APVdUPNns8qzFiLmO5NlX1v1X1BgZPE9ib5PWrOV+rQd/nsQ1jpaoudq+XgBMMtqfG2Xe6fdUr+6uXNnk8V62qvtP9w3wB+EvGaG26PeDPAX9dVZ/visdybUbNZZzXBqCq/hv4J2Afq1iXVoO+qUcvJNne/YKJJNuB24Anlu615Z0E3tO9fw/wd5s4llW58o+v8+uMydp0v/T7K+DrVfWnQ1VjtzaLzWUc1ybJZJKXde9/Dvg14BusYl2avOsGoLuN6s/46aMX/mhzR3T1kvwSg6t4GDy24r5xmk+SvwHexuBRq98Bfg/4W+CzwGuB/wR+q6q2/C85F5nL2xhsDRRwAfidK3upW1mSNwP/DDwOvNAV/y6Dve2xWpsl5nInY7Y2SW5g8MvWCQYX45+tqj9I8gqucl2aDXpJ0kCrWzeSpI5BL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhr3fxTc1NOz39LVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 30 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(len(fine_hist_normalized_np)), fine_hist_normalized_np)\n",
    "plt.show()\n",
    "plt.bar(np.arange(len(coarse_hist_normalized_np)), coarse_hist_normalized_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "234f3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "simCoef = np.corrcoef(fine_hist_normalized_np, coarse_hist_normalized_np)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eef0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4791f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_list_all = []\n",
    "hidden_channels = args.hidden_dim\n",
    "if dataset_name in ['brain']:\n",
    "    in_channels_nodes = 3\n",
    "    in_channels_edges = 1\n",
    "    num_classes = 8\n",
    "else:\n",
    "    try:\n",
    "        in_channels_nodes = dataset.num_node_features\n",
    "        in_channels_edges = dataset.num_edge_features\n",
    "        num_classes = dataset.num_classes\n",
    "    except:\n",
    "        in_channels_nodes = dataset_train.num_node_features\n",
    "        in_channels_edges = dataset_train.num_edge_features\n",
    "        num_classes = dataset_train.num_classes\n",
    "\n",
    "if dataset_name in ['MNIST', 'CIFAR10']:\n",
    "    in_channels_nodes += 2\n",
    "if in_channels_nodes == 0:\n",
    "    nodes_feature_flag = False\n",
    "    in_channels_nodes = 1\n",
    "else:\n",
    "    nodes_feature_flag = True\n",
    "\n",
    "if in_channels_edges == 0:\n",
    "    edge_feature_flag = False\n",
    "    in_channels_edges = 1\n",
    "else:\n",
    "    edge_feature_flag = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels_nodes, in_channels_edges, hidden_channels, num_classes, num_layers, edge_feature_flag):\n",
    "        super().__init__()\n",
    "        if edge_feature_flag:\n",
    "            self.net1 = GINENet(in_channels_nodes, in_channels_edges, hidden_channels, hidden_channels, num_layers)\n",
    "        else:\n",
    "            self.net1 = GINNet(in_channels_nodes, hidden_channels, hidden_channels, num_layers)\n",
    "            \n",
    "        self.net2 = GINENet(hidden_channels, hidden_channels, hidden_channels, num_classes, num_layers)\n",
    "        self.edge_feature_flag = edge_feature_flag\n",
    "        \n",
    "    def forward(self, \n",
    "                x_node, edge_index_node, edge_attr_node, batch_node,\n",
    "                x_edge, edge_index_edge, edge_attr_edge, batch_edge,\n",
    "                edge_index_cluster, batch_cluster):\n",
    "        if self.edge_feature_flag:\n",
    "            # with edge feature\n",
    "            edge_attr_cluster = self.net1(x_edge, edge_index_edge, edge_attr_edge, batch_edge)\n",
    "            x_cluster = self.net1(x_node, edge_index_node, edge_attr_node, batch_node)\n",
    "        else: \n",
    "            # no edge feature\n",
    "            edge_attr_cluster = self.net1(x_edge, edge_index_edge, batch_edge)\n",
    "            x_cluster = self.net1(x_node, edge_index_node, batch_node)\n",
    "            \n",
    "        out = self.net2(x_cluster, edge_index_cluster, edge_attr_cluster, batch_cluster)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8554de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClusterModel(\n",
    "    in_channels_nodes=in_channels_nodes, \n",
    "    in_channels_edges=in_channels_edges, \n",
    "    hidden_channels=hidden_channels, \n",
    "    num_classes=num_classes, \n",
    "    num_layers=args.number_layers,\n",
    "    edge_feature_flag=edge_feature_flag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fec044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusterModel(\n",
       "  (net1): GINENet(\n",
       "    (lin_init_node): MLP(\n",
       "      (mlp): ModuleList(\n",
       "        (0): Linear(9, 64, bias=True)\n",
       "        (1): Linear(64, 64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (lin_init_edge): MLP(\n",
       "      (mlp): ModuleList(\n",
       "        (0): Linear(3, 64, bias=True)\n",
       "        (1): Linear(64, 64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0): GINEConv(nn=MLP(\n",
       "        (mlp): ModuleList(\n",
       "          (0): Linear(64, 64, bias=True)\n",
       "          (1): Linear(64, 64, bias=True)\n",
       "        )\n",
       "      ))\n",
       "      (1): GINEConv(nn=MLP(\n",
       "        (mlp): ModuleList(\n",
       "          (0): Linear(64, 64, bias=True)\n",
       "          (1): Linear(64, 64, bias=True)\n",
       "        )\n",
       "      ))\n",
       "    )\n",
       "    (batch_norms): ModuleList(\n",
       "      (0): BatchNorm(64)\n",
       "    )\n",
       "  )\n",
       "  (net2): GINENet(\n",
       "    (lin_init_node): MLP(\n",
       "      (mlp): ModuleList(\n",
       "        (0): Linear(64, 64, bias=True)\n",
       "        (1): Linear(64, 64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (lin_init_edge): MLP(\n",
       "      (mlp): ModuleList(\n",
       "        (0): Linear(64, 64, bias=True)\n",
       "        (1): Linear(64, 64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0): GINEConv(nn=MLP(\n",
       "        (mlp): ModuleList(\n",
       "          (0): Linear(64, 64, bias=True)\n",
       "          (1): Linear(64, 64, bias=True)\n",
       "        )\n",
       "      ))\n",
       "      (1): GINEConv(nn=MLP(\n",
       "        (mlp): ModuleList(\n",
       "          (0): Linear(64, 64, bias=True)\n",
       "          (1): Linear(64, 2, bias=True)\n",
       "        )\n",
       "      ))\n",
       "    )\n",
       "    (batch_norms): ModuleList(\n",
       "      (0): BatchNorm(64)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b00441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbc0b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda:'+str(args.gpu))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()#torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "def train(batched_dataset_node, batched_dataset_edge, batched_clustered_edge_index, batched_clustered_batch, batched_y_true):\n",
    "    loss_value_list = []\n",
    "    model.train()\n",
    "    for data_node, data_edge, clustered_edge_index, clustered_batch, y_true in zip(batched_dataset_node, batched_dataset_edge, batched_clustered_edge_index, batched_clustered_batch, batched_y_true):\n",
    "        edge_index_node, batch_node = data_node.edge_index, data_node.batch\n",
    "        edge_index_edge, batch_edge = data_edge.edge_index, data_edge.batch\n",
    "        if nodes_feature_flag:\n",
    "            x_node = data_node.x.float()\n",
    "            x_edge = data_edge.x.float()\n",
    "        else:\n",
    "            x_node = torch.zeros((data_node.num_nodes, 1))\n",
    "            x_edge = torch.zeros((data_edge.num_nodes, 1))\n",
    "        if edge_feature_flag:\n",
    "            edge_attr_node = data_node.edge_attr.float()\n",
    "            edge_attr_edge = data_edge.edge_attr.float()\n",
    "        else:\n",
    "            edge_attr_node = torch.zeros((data_node.num_edges, 1))\n",
    "            edge_attr_edge = torch.zeros((data_edge.num_edges, 1))\n",
    "\n",
    "        x_node, edge_index_node, edge_attr_node, batch_node = x_node.to(device), edge_index_node.to(device), edge_attr_node.to(device), batch_node.to(device)\n",
    "        x_edge, edge_index_edge, edge_attr_edge, batch_edge = x_edge.to(device), edge_index_edge.to(device), edge_attr_edge.to(device), batch_edge.to(device) \n",
    "\n",
    "        if len(edge_attr_node.shape) == 1:\n",
    "            edge_attr_node = edge_attr_node.view(-1,1)\n",
    "            edge_attr_edge = edge_attr_edge.view(-1,1)\n",
    "        if dataset_name in ['MNIST', 'CIFAR10']:\n",
    "            pos_node = data_node.pos.float().to(device)\n",
    "            x_node = torch.cat([x_node, pos_node], dim=-1)\n",
    "            pos_edge = data_edge.pos.float().to(device)\n",
    "            x_edge = torch.cat([x_edge, pos_edge], dim=-1)\n",
    "        clustered_edge_index, clustered_batch = clustered_edge_index.to(device), clustered_batch.to(device)\n",
    "        y_true = y_true.view(-1).to(device)\n",
    "\n",
    "        out = model(\n",
    "            x_node, edge_index_node, edge_attr_node, batch_node,\n",
    "            x_edge, edge_index_edge, edge_attr_edge, batch_edge,\n",
    "            clustered_edge_index, clustered_batch\n",
    "        )\n",
    "        loss = criterion(out, y_true)  # Compute the loss.\n",
    "        loss_value = float(loss)\n",
    "        loss_value_list.append(loss_value)\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "    return loss_value_list\n",
    "\n",
    "def test(batched_dataset_node, batched_dataset_edge, batched_clustered_edge_index, batched_clustered_batch, batched_y_true):\n",
    "    y_pred_list = []\n",
    "    model.eval()\n",
    "    for data_node, data_edge, clustered_edge_index, clustered_batch, y_true in zip(batched_dataset_node, batched_dataset_edge, batched_clustered_edge_index, batched_clustered_batch, batched_y_true):\n",
    "        edge_index_node, batch_node = data_node.edge_index, data_node.batch\n",
    "        edge_index_edge, batch_edge = data_edge.edge_index, data_edge.batch\n",
    "        if nodes_feature_flag:\n",
    "            x_node = data_node.x.float()\n",
    "            x_edge = data_edge.x.float()\n",
    "        else:\n",
    "            x_node = torch.zeros((data_node.num_nodes, 1))\n",
    "            x_edge = torch.zeros((data_edge.num_nodes, 1))\n",
    "        if edge_feature_flag:\n",
    "            edge_attr_node = data_node.edge_attr.float()\n",
    "            edge_attr_edge = data_edge.edge_attr.float()\n",
    "        else:\n",
    "            edge_attr_node = torch.zeros((data_node.num_edges, 1))\n",
    "            edge_attr_edge = torch.zeros((data_edge.num_edges, 1))\n",
    "\n",
    "        x_node, edge_index_node, edge_attr_node, batch_node = x_node.to(device), edge_index_node.to(device), edge_attr_node.to(device), batch_node.to(device)\n",
    "        x_edge, edge_index_edge, edge_attr_edge, batch_edge = x_edge.to(device), edge_index_edge.to(device), edge_attr_edge.to(device), batch_edge.to(device) \n",
    "\n",
    "        if len(edge_attr_node.shape) == 1:\n",
    "            edge_attr_node = edge_attr_node.view(-1,1)\n",
    "            edge_attr_edge = edge_attr_edge.view(-1,1)\n",
    "        if dataset_name in ['MNIST', 'CIFAR10']:\n",
    "            pos_node = data_node.pos.float().to(device)\n",
    "            x_node = torch.cat([x_node, pos_node], dim=-1)\n",
    "            pos_edge = data_edge.pos.float().to(device)\n",
    "            x_edge = torch.cat([x_edge, pos_edge], dim=-1)\n",
    "        clustered_edge_index, clustered_batch = clustered_edge_index.to(device), clustered_batch.to(device)\n",
    "        out = model(\n",
    "            x_node, edge_index_node, edge_attr_node, batch_node,\n",
    "            x_edge, edge_index_edge, edge_attr_edge, batch_edge,\n",
    "            clustered_edge_index, clustered_batch\n",
    "        )\n",
    "        #pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        #y_pred_list.append(pred.detach().cpu())\n",
    "        out = out.softmax(dim=1)\n",
    "        y_pred_list.append(out.detach().cpu())\n",
    "\n",
    "    y_pred = torch.cat(y_pred_list)\n",
    "    return y_pred \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd155e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bace 5 1 64 2 0.0005\n",
      "Epoch, Loss, Train rocauc, Val rocauc, Test rocauc, Time\n",
      "000, 0.6907, 0.6520, 0.6886, 0.7602, 0.1841\n",
      "001, 0.6726, 0.6581, 0.6890, 0.7628, 0.3722\n",
      "002, 0.6676, 0.6621, 0.6941, 0.7625, 0.5363\n",
      "003, 0.6679, 0.6648, 0.7051, 0.7649, 0.7008\n",
      "004, 0.6715, 0.6692, 0.6967, 0.7675, 0.8606\n",
      "005, 0.6687, 0.6732, 0.7088, 0.7679, 1.0468\n",
      "006, 0.6727, 0.6741, 0.6978, 0.7672, 1.2469\n",
      "007, 0.6676, 0.6805, 0.7095, 0.7715, 1.4462\n",
      "008, 0.6701, 0.6786, 0.7103, 0.7734, 1.6238\n",
      "009, 0.6651, 0.6765, 0.7018, 0.7722, 1.8117\n",
      "010, 0.6629, 0.6827, 0.7022, 0.7746, 2.0111\n",
      "011, 0.6658, 0.6819, 0.7059, 0.7729, 2.1752\n",
      "012, 0.6663, 0.6826, 0.7048, 0.7734, 2.3439\n",
      "013, 0.6623, 0.6829, 0.7110, 0.7783, 2.5047\n",
      "014, 0.6634, 0.6819, 0.7048, 0.7769, 2.6653\n",
      "015, 0.6611, 0.6866, 0.7029, 0.7823, 2.8523\n",
      "016, 0.6625, 0.6878, 0.6971, 0.7795, 3.0147\n",
      "017, 0.6579, 0.6920, 0.6967, 0.7849, 3.1775\n",
      "018, 0.6613, 0.6934, 0.7040, 0.7820, 3.3399\n",
      "019, 0.6568, 0.6938, 0.6974, 0.7879, 3.5079\n",
      "020, 0.6589, 0.6953, 0.6989, 0.7893, 3.6681\n",
      "021, 0.6542, 0.6953, 0.6956, 0.7912, 3.8611\n",
      "022, 0.6591, 0.6960, 0.6956, 0.7839, 4.0619\n",
      "023, 0.6541, 0.6966, 0.6938, 0.7849, 4.2695\n",
      "024, 0.6580, 0.6959, 0.6864, 0.7842, 4.4790\n",
      "025, 0.6602, 0.7019, 0.6912, 0.7948, 4.6663\n",
      "026, 0.6518, 0.6948, 0.6919, 0.7877, 4.8120\n",
      "027, 0.6636, 0.7010, 0.6960, 0.7872, 4.9563\n",
      "028, 0.6535, 0.6993, 0.6949, 0.7847, 5.1104\n",
      "029, 0.6493, 0.7011, 0.6890, 0.7879, 5.3072\n",
      "030, 0.6535, 0.7069, 0.6886, 0.7927, 5.4784\n",
      "031, 0.6486, 0.7048, 0.6883, 0.7894, 5.6475\n",
      "032, 0.6491, 0.7065, 0.6952, 0.7920, 5.8118\n",
      "033, 0.6515, 0.7023, 0.6791, 0.7868, 5.9784\n",
      "034, 0.6490, 0.6953, 0.6853, 0.7943, 6.1377\n",
      "035, 0.6811, 0.6812, 0.6813, 0.7913, 6.3343\n",
      "036, 0.7334, 0.6368, 0.5941, 0.7820, 6.4947\n",
      "037, 0.7144, 0.6640, 0.6469, 0.7800, 6.7083\n",
      "038, 0.7486, 0.3546, 0.3187, 0.2528, 6.9144\n",
      "039, 0.9837, 0.6214, 0.5264, 0.6524, 7.1308\n",
      "040, 0.7629, 0.6446, 0.5930, 0.7545, 7.3528\n",
      "041, 0.6646, 0.5054, 0.3996, 0.6131, 7.5025\n",
      "042, 0.7864, 0.6915, 0.6718, 0.7694, 7.6471\n",
      "043, 0.6648, 0.6897, 0.6850, 0.7519, 7.7908\n",
      "044, 0.6856, 0.6638, 0.6960, 0.7519, 7.9352\n",
      "045, 0.6703, 0.6765, 0.6857, 0.7562, 8.0800\n",
      "046, 0.6622, 0.6820, 0.6886, 0.7602, 8.2249\n",
      "047, 0.6557, 0.6848, 0.6868, 0.7635, 8.3690\n",
      "048, 0.6544, 0.6856, 0.6864, 0.7630, 8.5141\n",
      "049, 0.6541, 0.6860, 0.6868, 0.7649, 8.6595\n",
      "050, 0.6532, 0.6876, 0.6846, 0.7689, 8.8046\n",
      "051, 0.6515, 0.6893, 0.6835, 0.7713, 8.9485\n",
      "052, 0.6498, 0.6908, 0.6853, 0.7748, 9.0929\n",
      "053, 0.6480, 0.6916, 0.6817, 0.7778, 9.2369\n",
      "054, 0.6469, 0.6932, 0.6832, 0.7814, 9.3812\n",
      "055, 0.6451, 0.6929, 0.6777, 0.7804, 9.5254\n",
      "056, 0.6453, 0.6969, 0.6824, 0.7858, 9.6708\n",
      "057, 0.6423, 0.6929, 0.6780, 0.7793, 9.8155\n",
      "058, 0.6449, 0.7013, 0.6802, 0.7877, 10.0107\n",
      "059, 0.6402, 0.6953, 0.6747, 0.7823, 10.2252\n",
      "060, 0.6435, 0.7021, 0.6813, 0.7866, 10.4373\n",
      "061, 0.6384, 0.6995, 0.6766, 0.7860, 10.5828\n",
      "062, 0.6384, 0.6993, 0.6751, 0.7833, 10.7334\n",
      "063, 0.6398, 0.7051, 0.6758, 0.7887, 10.8955\n",
      "064, 0.6353, 0.7011, 0.6769, 0.7853, 11.0585\n",
      "065, 0.6383, 0.7093, 0.6769, 0.7893, 11.2302\n",
      "066, 0.6325, 0.7013, 0.6707, 0.7847, 11.4010\n",
      "067, 0.6413, 0.7130, 0.6729, 0.7893, 11.6278\n",
      "068, 0.6319, 0.7012, 0.6718, 0.7840, 11.7945\n",
      "069, 0.6410, 0.7142, 0.6769, 0.7906, 11.9563\n",
      "070, 0.6300, 0.7103, 0.6747, 0.7875, 12.1161\n",
      "071, 0.6337, 0.7139, 0.6747, 0.7889, 12.2785\n",
      "072, 0.6311, 0.7164, 0.6740, 0.7896, 12.4777\n",
      "073, 0.6299, 0.7184, 0.6729, 0.7894, 12.6389\n",
      "074, 0.6291, 0.7212, 0.6729, 0.7882, 12.8539\n",
      "075, 0.6272, 0.7221, 0.6711, 0.7893, 13.0696\n",
      "076, 0.6281, 0.7255, 0.6762, 0.7913, 13.2855\n",
      "077, 0.6253, 0.7238, 0.6659, 0.7906, 13.4951\n",
      "078, 0.6295, 0.7284, 0.6821, 0.7967, 13.6809\n",
      "079, 0.6231, 0.7063, 0.6590, 0.7832, 13.8441\n",
      "080, 0.6553, 0.6002, 0.4198, 0.7011, 14.0041\n",
      "081, 0.6515, 0.6912, 0.6930, 0.7922, 14.1655\n",
      "082, 0.6998, 0.6893, 0.6747, 0.7797, 14.3259\n",
      "083, 0.6572, 0.7023, 0.6700, 0.7840, 14.4879\n",
      "084, 0.6320, 0.7083, 0.6678, 0.7835, 14.6477\n",
      "085, 0.6271, 0.7123, 0.6718, 0.7865, 14.8351\n",
      "086, 0.6313, 0.7175, 0.6707, 0.7886, 15.0160\n",
      "087, 0.6225, 0.7203, 0.6733, 0.7870, 15.2001\n",
      "088, 0.6222, 0.7231, 0.6722, 0.7889, 15.4027\n",
      "089, 0.6219, 0.7262, 0.6696, 0.7898, 15.5667\n",
      "090, 0.6193, 0.7285, 0.6703, 0.7887, 15.7325\n",
      "091, 0.6187, 0.7321, 0.6685, 0.7894, 15.8881\n",
      "092, 0.6149, 0.7331, 0.6681, 0.7903, 16.0474\n",
      "093, 0.6175, 0.7370, 0.6692, 0.7910, 16.2060\n",
      "094, 0.6129, 0.7376, 0.6703, 0.7922, 16.3672\n",
      "095, 0.6144, 0.7410, 0.6714, 0.7943, 16.5258\n",
      "096, 0.6129, 0.7433, 0.6733, 0.7950, 16.7207\n",
      "097, 0.6085, 0.7435, 0.6711, 0.7922, 16.8962\n",
      "098, 0.6154, 0.7487, 0.6714, 0.7960, 17.0496\n",
      "099, 0.6038, 0.7432, 0.6707, 0.7905, 17.2320\n",
      "100, 0.6165, 0.7521, 0.6696, 0.7976, 17.3749\n",
      "101, 0.6061, 0.7445, 0.6744, 0.7908, 17.5161\n",
      "102, 0.6162, 0.7571, 0.6711, 0.8006, 17.6608\n",
      "103, 0.6063, 0.7426, 0.6784, 0.7941, 17.8548\n",
      "104, 0.6144, 0.7591, 0.6645, 0.8000, 17.9988\n",
      "105, 0.5964, 0.7220, 0.6791, 0.7804, 18.1401\n",
      "106, 0.6673, 0.7112, 0.5689, 0.7750, 18.2927\n",
      "107, 0.6290, 0.7290, 0.6648, 0.8032, 18.4468\n",
      "108, 0.6242, 0.7402, 0.6707, 0.7811, 18.6064\n",
      "109, 0.6100, 0.7566, 0.6645, 0.7797, 18.7655\n",
      "110, 0.5991, 0.7562, 0.6718, 0.7830, 18.9520\n",
      "111, 0.6060, 0.7649, 0.6659, 0.7896, 19.1099\n",
      "112, 0.5912, 0.7610, 0.6733, 0.7877, 19.2656\n",
      "113, 0.6033, 0.7734, 0.6575, 0.7939, 19.4176\n",
      "114, 0.5833, 0.7611, 0.6762, 0.7854, 19.5685\n",
      "115, 0.6102, 0.7767, 0.6480, 0.7988, 19.7195\n",
      "116, 0.5801, 0.7601, 0.6810, 0.7839, 19.9196\n",
      "117, 0.6178, 0.7801, 0.6476, 0.8011, 20.0717\n",
      "118, 0.5834, 0.7562, 0.6875, 0.7788, 20.2738\n",
      "119, 0.6166, 0.7779, 0.6407, 0.8026, 20.4517\n",
      "120, 0.5898, 0.7231, 0.6773, 0.7534, 20.6036\n",
      "121, 0.6610, 0.7327, 0.5520, 0.7799, 20.7554\n",
      "122, 0.6088, 0.7472, 0.6725, 0.7807, 20.9160\n",
      "123, 0.6308, 0.7238, 0.5813, 0.7578, 21.0698\n",
      "124, 0.5928, 0.7419, 0.6696, 0.7527, 21.2535\n",
      "125, 0.6799, 0.7801, 0.6637, 0.7811, 21.3950\n",
      "126, 0.5825, 0.7469, 0.6963, 0.7712, 21.5362\n",
      "127, 0.6129, 0.7889, 0.6769, 0.7832, 21.6773\n",
      "128, 0.5759, 0.7758, 0.6916, 0.7621, 21.8192\n",
      "129, 0.5931, 0.7892, 0.6842, 0.7682, 21.9600\n",
      "130, 0.5726, 0.7850, 0.6828, 0.7712, 22.1014\n",
      "131, 0.5833, 0.7944, 0.6788, 0.7771, 22.2425\n",
      "132, 0.5657, 0.7890, 0.6835, 0.7647, 22.3838\n",
      "133, 0.5834, 0.8021, 0.6718, 0.7741, 22.5247\n",
      "134, 0.5600, 0.7909, 0.6806, 0.7567, 22.6662\n",
      "135, 0.5869, 0.8058, 0.6740, 0.7708, 22.8069\n",
      "136, 0.5612, 0.7925, 0.6864, 0.7524, 22.9481\n",
      "137, 0.5851, 0.8099, 0.6678, 0.7658, 23.0890\n",
      "138, 0.5601, 0.7968, 0.6894, 0.7541, 23.2650\n",
      "139, 0.5816, 0.8133, 0.6505, 0.7621, 23.4805\n",
      "140, 0.5523, 0.7842, 0.6919, 0.7472, 23.6906\n",
      "141, 0.6075, 0.7838, 0.5604, 0.7324, 23.8328\n",
      "142, 0.5812, 0.7196, 0.6960, 0.7018, 23.9741\n",
      "143, 0.7334, 0.6160, 0.3993, 0.6413, 24.1151\n",
      "144, 0.6774, 0.6621, 0.4850, 0.6795, 24.2565\n",
      "145, 0.6942, 0.4877, 0.3769, 0.4592, 24.3974\n",
      "146, 0.8005, 0.7349, 0.6722, 0.7258, 24.5388\n",
      "147, 0.6632, 0.7408, 0.6751, 0.7449, 24.6799\n",
      "148, 0.5925, 0.7321, 0.6901, 0.7373, 24.8221\n",
      "149, 0.6485, 0.7632, 0.6780, 0.7480, 24.9637\n",
      "150, 0.5851, 0.7630, 0.6791, 0.7477, 25.1052\n",
      "151, 0.5826, 0.7638, 0.6707, 0.7460, 25.2462\n",
      "152, 0.5974, 0.7784, 0.6736, 0.7538, 25.3875\n",
      "153, 0.5731, 0.7770, 0.6777, 0.7536, 25.5284\n",
      "154, 0.5826, 0.7851, 0.6773, 0.7578, 25.6706\n",
      "155, 0.5662, 0.7832, 0.6810, 0.7520, 25.8116\n",
      "156, 0.5784, 0.7907, 0.6784, 0.7614, 25.9538\n",
      "157, 0.5588, 0.7874, 0.6806, 0.7529, 26.0947\n",
      "158, 0.5739, 0.7952, 0.6791, 0.7600, 26.2370\n",
      "159, 0.5553, 0.7923, 0.6813, 0.7538, 26.3780\n",
      "160, 0.5677, 0.7997, 0.6842, 0.7604, 26.5199\n",
      "161, 0.5522, 0.7964, 0.6857, 0.7553, 26.6609\n",
      "162, 0.5670, 0.8042, 0.6853, 0.7597, 26.8027\n",
      "163, 0.5461, 0.7995, 0.6897, 0.7541, 26.9434\n",
      "164, 0.5651, 0.8087, 0.6824, 0.7592, 27.0853\n",
      "165, 0.5408, 0.8022, 0.6883, 0.7533, 27.2261\n",
      "166, 0.5645, 0.8124, 0.6832, 0.7630, 27.3678\n",
      "167, 0.5364, 0.8017, 0.6886, 0.7500, 27.5086\n",
      "168, 0.5727, 0.8151, 0.6806, 0.7609, 27.6506\n",
      "169, 0.5361, 0.7981, 0.6949, 0.7467, 27.7915\n",
      "170, 0.5811, 0.8164, 0.6623, 0.7527, 27.9336\n",
      "171, 0.5414, 0.7884, 0.6982, 0.7447, 28.0746\n",
      "172, 0.5908, 0.8060, 0.6201, 0.7479, 28.2165\n",
      "173, 0.5403, 0.8024, 0.6974, 0.7560, 28.3578\n",
      "174, 0.5677, 0.8174, 0.6674, 0.7588, 28.5214\n",
      "175, 0.5239, 0.8107, 0.6861, 0.7538, 28.7327\n",
      "176, 0.5607, 0.8232, 0.6711, 0.7606, 28.9487\n",
      "177, 0.5192, 0.8146, 0.6916, 0.7507, 29.1029\n",
      "178, 0.5554, 0.8237, 0.6454, 0.7593, 29.2543\n",
      "179, 0.5304, 0.8090, 0.6813, 0.7536, 29.4049\n",
      "180, 0.5640, 0.8193, 0.6260, 0.7508, 29.5580\n",
      "181, 0.5253, 0.8152, 0.6868, 0.7520, 29.7120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182, 0.5574, 0.8312, 0.6729, 0.7482, 29.8664\n",
      "183, 0.5056, 0.8206, 0.6879, 0.7531, 30.0216\n",
      "184, 0.5638, 0.8310, 0.6850, 0.7427, 30.1781\n",
      "185, 0.5059, 0.8225, 0.6795, 0.7560, 30.3294\n",
      "186, 0.5540, 0.8362, 0.6667, 0.7447, 30.4819\n",
      "187, 0.4995, 0.8228, 0.6861, 0.7409, 30.6228\n",
      "188, 0.5624, 0.8305, 0.6341, 0.7461, 30.7645\n",
      "189, 0.5170, 0.8171, 0.6853, 0.7508, 30.9059\n",
      "190, 0.5555, 0.8316, 0.6502, 0.7454, 31.0472\n",
      "191, 0.5478, 0.8057, 0.7011, 0.7390, 31.1880\n",
      "192, 0.5535, 0.8224, 0.6150, 0.7388, 31.3290\n",
      "193, 0.5399, 0.8211, 0.6978, 0.7613, 31.4697\n",
      "194, 0.5265, 0.8367, 0.6480, 0.7395, 31.6111\n",
      "195, 0.4999, 0.8334, 0.6846, 0.7574, 31.7514\n",
      "196, 0.5486, 0.8378, 0.6260, 0.7385, 31.8918\n",
      "197, 0.4943, 0.8249, 0.6883, 0.7519, 32.0318\n",
      "198, 0.5722, 0.8279, 0.5923, 0.7291, 32.1722\n",
      "199, 0.5203, 0.8269, 0.6978, 0.7541, 32.3125\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "test_accuracy_list = []\n",
    "\n",
    "directory = os.path.join(args.write_dir, args.dataset, str(args.num_clusters), str(args.idx), str(args.hidden_dim)+'_'+str(args.number_layers)+'_'+str(args.lr))\n",
    "print(args.dataset, str(args.num_clusters), str(args.idx), str(args.hidden_dim), str(args.number_layers), str(args.lr))\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "f = open(os.path.join(directory, 'log.txt'), 'a')\n",
    "if dataset_name in ['hiv', 'bace', 'bbbp', 'UPFD']:\n",
    "    print('Epoch, Loss, Train rocauc, Val rocauc, Test rocauc, Time')\n",
    "elif dataset_name in ['MNIST', 'CIFAR10']:\n",
    "    print('Epoch, Loss, Train Accuracy, Val Accuracy, Test Accuracy, Time')\n",
    "else:\n",
    "    print('Epoch, Loss, Train Accuracy, Test Accuracy, Time')\n",
    "\n",
    "results = []\n",
    "for epoch in (range(200)):\n",
    "    loss_value_list = train(batched_dataset_train_node, batched_dataset_train_edge, clustered_edge_index_train, clustered_batch_train, y_true_train)\n",
    "    y_pred_train = test(batched_dataset_train_node, batched_dataset_train_edge, clustered_edge_index_train, clustered_batch_train, y_true_train)\n",
    "    y_pred_test = test(batched_dataset_test_node, batched_dataset_test_edge, clustered_edge_index_test, clustered_batch_test, y_true_test)\n",
    "\n",
    "    loss_value = np.mean(loss_value_list)\n",
    "\n",
    "    # reshape y_true\n",
    "    y_true_train_1d = torch.cat(y_true_train).view(-1).numpy()\n",
    "    y_true_test_1d = torch.cat(y_true_test).view(-1).numpy()\n",
    "    y_true_train_2d = np.zeros((y_true_train_1d.size, y_true_train_1d.max()+1))\n",
    "    y_true_train_2d[np.arange(y_true_train_1d.size),y_true_train_1d] = 1\n",
    "    y_true_test_2d = np.zeros((y_true_test_1d.size, y_true_test_1d.max()+1))\n",
    "    y_true_test_2d[np.arange(y_true_test_1d.size),y_true_test_1d] = 1\n",
    "\n",
    "    if dataset_name in ['MNIST', 'CIFAR10', 'hiv', 'bace', 'bbbp', 'UPFD']:\n",
    "        y_pred_val = test(batched_dataset_val_node, batched_dataset_val_edge, clustered_edge_index_val, clustered_batch_val, y_true_val)\n",
    "        y_true_val_1d = torch.cat(y_true_val).view(-1).numpy()\n",
    "        y_true_val_2d = np.zeros((y_true_val_1d.size, y_true_val_1d.max()+1))\n",
    "        y_true_val_2d[np.arange(y_true_val_1d.size),y_true_val_1d] = 1\n",
    "\n",
    "    if dataset_name in ['hiv', 'bace', 'bbbp', 'UPFD']:\n",
    "        train_accuracy = roc_auc_score(y_true_train_2d, y_pred_train.numpy())\n",
    "        val_accuracy = roc_auc_score(y_true_val_2d, y_pred_val.numpy())\n",
    "        test_accuracy = roc_auc_score(y_true_test_2d, y_pred_test.numpy())\n",
    "        results.append([epoch, loss_value, train_accuracy, val_accuracy, test_accuracy, time.time()-start_time])\n",
    "        print(\"{:03d}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format(epoch, loss_value, train_accuracy, val_accuracy, test_accuracy, time.time()-start_time))\n",
    "    elif dataset_name in ['MNIST', 'CIFAR10']:\n",
    "        y_pred_train, y_pred_val, y_pred_test = y_pred_train.argmax(dim=1), y_pred_val.argmax(dim=1), y_pred_test.argmax(dim=1)\n",
    "        train_accuracy = accuracy_score(y_true_train_1d, y_pred_train.numpy())\n",
    "        val_accuracy = accuracy_score(y_true_val_1d, y_pred_val.numpy())\n",
    "        test_accuracy = accuracy_score(y_true_test_1d, y_pred_test.numpy())\n",
    "        results.append([epoch, loss_value, train_accuracy, val_accuracy, test_accuracy, time.time()-start_time])\n",
    "        print(\"{:03d}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format(epoch, loss_value, train_accuracy, val_accuracy, test_accuracy, time.time()-start_time))\n",
    "    else:\n",
    "        y_pred_train, y_pred_test = y_pred_train.argmax(dim=1), y_pred_test.argmax(dim=1)\n",
    "        train_accuracy = accuracy_score(y_true_train_1d, y_pred_train.numpy())\n",
    "        test_accuracy = accuracy_score(y_true_test_1d, y_pred_test.numpy())\n",
    "        results.append([epoch, loss_value, train_accuracy, test_accuracy, time.time()-start_time])\n",
    "        print(\"{:03d}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format(epoch, loss_value, train_accuracy, test_accuracy, time.time()-start_time))\n",
    "\n",
    "if dataset_name in ['hiv', 'bace', 'bbbp', 'UPFD']:\n",
    "    df = pd.DataFrame(data=results, columns=['Epoch', 'Loss', 'Train rocauc', 'Val rocauc', 'Test rocauc', 'Time'])\n",
    "elif dataset_name in ['MNIST', 'CIFAR10']:\n",
    "    df = pd.DataFrame(data=results, columns=['Epoch', 'Loss', 'Train Accuracy', 'Val Accuracy', 'Test Accuracy', 'Time'])\n",
    "else:\n",
    "    df = pd.DataFrame(data=results, columns=['Epoch', 'Loss', 'Train Accuracy', 'Test Accuracy', 'Time'])\n",
    "\n",
    "#df.to_csv(os.path.join(directory, 'results.csv'), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f4d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
